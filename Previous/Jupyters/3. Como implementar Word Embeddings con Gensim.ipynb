{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color=\"#113D68\" size=5>Deep Learning para Procesamiento del Lenguaje Natural</font></h1>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#113D68\" size=6>Como implementar Word Embeddings con Gensim</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#113D68\" size=3>Manuel Castillo Cara</font><br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "\n",
    "* [1. Word Embeddings](#section1)\n",
    "    * [1.1. Biblioteca de Python de Gensim](#section11)\n",
    "    * [1.2. Desarrollar la incrustación de Word2Vec](#section12)\n",
    "    * [1.3. Visualizar Word Embeddings](#section13)\n",
    "    * [1.4. Cargar el Embedding de Word2Vec de Google](#section14)\n",
    "    * [1.5. Cargue la incrustación GloVe de Stanford](#section15)\n",
    "* [2. Word Embedding en Keras](#section2)\n",
    "    * [2.1. Ejemplo de aprendizaje de Embedding](#section21)\n",
    "    * [2.2. Ejemplo de uso de GloVe preentrenado](#section22)\n",
    "* [Ejercicios](#sectionEJ)\n",
    "    * [Ejercicio 1](#sectionEJ1)\n",
    "    * [Ejercicio 2](#sectionEJ2)\n",
    "    * [Ejercicio 3](#sectionEJ3)\n",
    "    * [Ejercicio 4](#sectionEJ4)\n",
    "    * [Ejercicio 5](#sectionEJ5)\n",
    "    * [Ejercicio 6](#sectionEJ6)\n",
    "    * [Ejercicio 7](#sectionEJ7)\n",
    "    * [Ejercicio 8](#sectionEJ8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 1. Word Embeddings</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las incrustaciones de palabras son un enfoque moderno para representar texto en el procesamiento del lenguaje natural. Los algoritmos integrados como _Word2Vec_ y _GloVe_ son clave para los resultados de vanguardia logrados por los modelos de redes neuronales en problemas de procesamiento del lenguaje natural como la traducción automática.\n",
    "\n",
    "En este tutorial, descubrirá cómo entrenar y cargar modelos de incrustación de palabras para aplicaciones de procesamiento de lenguaje natural en Python usando `Gensim`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section11\"></a>\n",
    "# <font color=\"#004D7F\" size=5>1.1. Biblioteca de Python de `Gensim`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Gensim` es una biblioteca Python de código abierto para el procesamiento del lenguaje natural, con un enfoque en el modelado de temas. \n",
    "\n",
    "No es una biblioteca de investigación de NLP que incluye todo (como NLTK); en cambio, `Gensim` es un conjunto de herramientas de NLP maduras, enfocadas y eficientes para el modelado de temas. Admite una implementación de Word Embeddings _Word2Vec_ para aprender nuevos vectores de palabras a partir del texto.\n",
    "\n",
    "También proporciona herramientas para cargar Word Embedding previamente entrenadas en algunos formatos y para utilizar y consultar una incrustación cargada. \n",
    "\n",
    "Puede instalar `Gensim` con `pip` escribiendo lo siguiente en su línea de comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/manwest/Documentos/Jupyter/jupyterEnv/lib/python3.8/site-packages (4.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/manwest/Documentos/Jupyter/jupyterEnv/lib/python3.8/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/manwest/Documentos/Jupyter/jupyterEnv/lib/python3.8/site-packages (from gensim) (1.22.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/manwest/Documentos/Jupyter/jupyterEnv/lib/python3.8/site-packages (from gensim) (1.8.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Words Embeddings en [Wikipedia](https://en.wikipedia.org/wiki/Word_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Instrucciones de instalación de [`Gensim`](https://radimrehurek.com/gensim/install.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Biblioteca Python [`Gensim`](https://radimrehurek.com/gensim/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a>\n",
    "# <font color=\"#004D7F\" size=5>1.2. Desarrollar la incrustación de _Word2Vec_</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Word2Vec_ es un algoritmo para aprender una palabra incrustada a partir de un corpus de texto. Hay dos algoritmos de entrenamiento principales que se pueden usar para aprender la incrustación del texto; **son Bolsa de palabras continua (CBOW) y skip-grams**. Los modelos de _Word2Vec_ requieren mucho texto, por ejemplo, todo el corpus de Wikipedia. Sin embargo, demostraremos los principios usando un pequeño ejemplo de texto en la memoria. \n",
    "\n",
    "`Gensim` proporciona la clase `_Word2Vec` para trabajar con un modelo _Word2Vec_. Aprender un word Embedding a partir del texto implica cargar y organizar el texto en oraciones y proporcionarlas al constructor de una nueva instancia de `Word2Vec()`. Por ejemplo:\n",
    "\n",
    "```python\n",
    "    sentences =     ...\n",
    "    model = Word2Vec(sentences)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Específicamente, cada oración debe ser tokenizada, es decir, dividida en palabras y preparada (por ejemplo, quizás prefiltrada y quizás convertida a un caso preferido). Las oraciones pueden ser\n",
    "- Texto cargado en la memoria, o \n",
    "- Un iterador que carga texto progresivamente, requerido para corpus de texto muy grandes. \n",
    "\n",
    "Hay muchos parámetros en este constructor; algunos argumentos dignos de mención que puede desear configurar son:\n",
    "- __`size`__ (predeterminado 100): El número de dimensiones de la incrustación, por ejemplo, la longitud del vector denso para representar cada token (palabra).\n",
    "- __`window`__ (predeterminado 5): La distancia máxima entre una palabra objetivo y las palabras alrededor de la palabra objetivo. \n",
    "- __`min_count`__ (predeterminado 5): El recuento mínimo de palabras a considerar al entrenar el modelo; las palabras con una aparición menor que este número serán ignoradas.\n",
    "- __`workers`__ (predeterminado 3): El número de subprocesos a usar durante el entrenamiento.\n",
    "- __`sg`__ (predeterminado 0 o CBOW): El algoritmo de entrenamiento, ya sea CBOW (0) o salto de gram (1).\n",
    "\n",
    "Por ejemplo, puede imprimir el vocabulario aprendido de tokens (palabras) de la siguiente manera:\n",
    "\n",
    "```python\n",
    "    words = model.wv.index_to_key\n",
    "    print(words)\n",
    "```\n",
    "\n",
    "Puede revisar el vector incrustado para un token específico de la siguiente manera:\n",
    "\n",
    "```python\n",
    "    print(model.wv['word'])\n",
    "```\n",
    "\n",
    "Finalmente, un modelo entrenado se puede guardar en un archivo llamando a la función `save_word2vec_format()` en el modelo de vector de palabra. De forma predeterminada, el modelo se guarda en formato binario para ahorrar espacio. Por ejemplo:\n",
    "\n",
    "```python\n",
    "    model.wv.save_word2vec_format('model.bin')\n",
    "```\n",
    "\n",
    "Al comenzar, puede guardar el modelo aprendido en formato ASCII y revisar el contenido. Puede hacer esto configurando `binary=False` al llamar a la función `save_word2vec_format()`, por ejemplo:\n",
    "\n",
    "```python\n",
    "    model.wv.save_word2vec_format('model.txt', binary=False)\n",
    "```\n",
    "\n",
    "El modelo guardado se puede volver a cargar llamando a la función `Word2Vec.load()`. Por ejemplo:\n",
    "\n",
    "```python\n",
    "    model = Word2Vec.load('model.bin')\n",
    "```\n",
    "\n",
    "Podemos unir todo esto con un ejemplo resuelto. \n",
    "- En lugar de cargar un documento de texto grande o un corpus desde un archivo, trabajaremos con una pequeña lista en memoria de oraciones preidentificadas. \n",
    "- El modelo está entrenado y el recuento mínimo de palabras se establece en 1 para que no se ignore ninguna palabra. \n",
    "- Después de aprender el modelo, resumimos, imprimimos el vocabulario y luego imprimimos un solo vector para la palabra _\"sentence\"_. \n",
    "- Finalmente, el modelo se guarda en un archivo en formato binario, se carga y luego se resume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Word2Vec en [Wikipedia](https://en.wikipedia.org/wiki/Word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=14, vector_size=100, alpha=0.025>\n",
      "14\n",
      "['sentence', 'the', 'is', 'this', 'final', 'and', 'more', 'one', 'another', 'yet', 'second', 'word2vec', 'for', 'first']\n",
      "\n",
      " access vector for one word\n",
      "[-5.3622725e-04  2.3643136e-04  5.1033497e-03  9.0092728e-03\n",
      " -9.3029495e-03 -7.1168090e-03  6.4588725e-03  8.9729885e-03\n",
      " -5.0154282e-03 -3.7633716e-03  7.3805046e-03 -1.5334714e-03\n",
      " -4.5366134e-03  6.5540518e-03 -4.8601604e-03 -1.8160177e-03\n",
      "  2.8765798e-03  9.9187379e-04 -8.2852151e-03 -9.4488179e-03\n",
      "  7.3117660e-03  5.0702621e-03  6.7576934e-03  7.6286553e-04\n",
      "  6.3508903e-03 -3.4053659e-03 -9.4640139e-04  5.7685734e-03\n",
      " -7.5216377e-03 -3.9361035e-03 -7.5115822e-03 -9.3004224e-04\n",
      "  9.5381187e-03 -7.3191668e-03 -2.3337686e-03 -1.9377411e-03\n",
      "  8.0774371e-03 -5.9308959e-03  4.5162440e-05 -4.7537340e-03\n",
      " -9.6035507e-03  5.0072931e-03 -8.7595852e-03 -4.3918253e-03\n",
      " -3.5099984e-05 -2.9618145e-04 -7.6612402e-03  9.6147433e-03\n",
      "  4.9820580e-03  9.2331432e-03 -8.1579173e-03  4.4957981e-03\n",
      " -4.1370760e-03  8.2453608e-04  8.4986202e-03 -4.4621765e-03\n",
      "  4.5175003e-03 -6.7869602e-03 -3.5484887e-03  9.3985079e-03\n",
      " -1.5776526e-03  3.2137157e-04 -4.1406299e-03 -7.6826881e-03\n",
      " -1.5080082e-03  2.4697948e-03 -8.8802696e-04  5.5336617e-03\n",
      " -2.7429771e-03  2.2600652e-03  5.4557943e-03  8.3459532e-03\n",
      " -1.4537406e-03 -9.2081428e-03  4.3705525e-03  5.7178497e-04\n",
      "  7.4419081e-03 -8.1328274e-04 -2.6384138e-03 -8.7530091e-03\n",
      " -8.5655687e-04  2.8265631e-03  5.4014288e-03  7.0526563e-03\n",
      " -5.7031214e-03  1.8588197e-03  6.0888636e-03 -4.7980510e-03\n",
      " -3.1072604e-03  6.7976294e-03  1.6314756e-03  1.8991709e-04\n",
      "  3.4736372e-03  2.1777749e-04  9.6188262e-03  5.0606038e-03\n",
      " -8.9173904e-03 -7.0415605e-03  9.0145587e-04  6.3925339e-03]\n",
      "\n",
      " access vector for all words\n",
      "[[-5.3622725e-04  2.3643136e-04  5.1033497e-03 ... -7.0415605e-03\n",
      "   9.0145587e-04  6.3925339e-03]\n",
      " [-8.6196875e-03  3.6657380e-03  5.1898835e-03 ... -2.3915148e-03\n",
      "  -9.5100943e-03  4.5058788e-03]\n",
      " [ 9.4563962e-05  3.0773198e-03 -6.8126451e-03 ...  5.1259040e-04\n",
      "   8.2130842e-03 -7.0190406e-03]\n",
      " ...\n",
      " [ 9.7702928e-03  8.1651136e-03  1.2809718e-03 ... -2.9727400e-03\n",
      "  -4.9318983e-03 -2.3151112e-03]\n",
      " [-1.9442164e-03 -5.2675214e-03  9.4471136e-03 ...  5.9827138e-03\n",
      "   6.8153618e-03  7.8225443e-03]\n",
      " [-9.5001198e-03  9.5622232e-03 -7.7707553e-03 ... -3.1351077e-03\n",
      "  -6.3388194e-03  9.8700775e-03]]\n",
      "\n",
      " index of each words\n",
      "{'sentence': 0, 'the': 1, 'is': 2, 'this': 3, 'final': 4, 'and': 5, 'more': 6, 'one': 7, 'another': 8, 'yet': 9, 'second': 10, 'word2vec': 11, 'for': 12, 'first': 13}\n",
      "Word2Vec<vocab=14, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# define training data\n",
    "sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
    "\t\t\t['this', 'is', 'the', 'second', 'sentence'],\n",
    "\t\t\t['yet', 'another', 'sentence'],\n",
    "\t\t\t['one', 'more', 'sentence'],\n",
    "\t\t\t['and', 'the', 'final', 'sentence']]\n",
    "# train model\n",
    "model = Word2Vec(sentences, min_count=1)\n",
    "# summarize the loaded model\n",
    "print(model)\n",
    "# print number of vocals\n",
    "print(len(model.wv))\n",
    "# summarize vocabulary\n",
    "words = model.wv.index_to_key\n",
    "print(words)\n",
    "# access vector for one word\n",
    "print(\"\\n access vector for one word\")\n",
    "print(model.wv['sentence'])\n",
    "# access vector for all words\n",
    "print(\"\\n access vector for all words\")\n",
    "print(model.wv.vectors)\n",
    "# index of each words\n",
    "print(\"\\n index of each words\")\n",
    "print(model.wv.key_to_index)\n",
    "# save model\n",
    "model.save('model.bin')\n",
    "# load model\n",
    "new_model = Word2Vec.load('model.bin')\n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes ver que con un poco de trabajo para preparar tu documento de texto, puedes crear tu propio Word Embedding muy fácilmente con `Gensim`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Información sobre la API Gensim [`models.word2vec`](https://radimrehurek.com/gensim/models/keyedvectors.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Información sobre la API Gensim [`models.keyedvectors`](https://radimrehurek.com/gensim/models/keyedvectors.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section13\"></a>\n",
    "# <font color=\"#004D7F\" size=5>1.3. Visualizar Word Embeddings</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos crear un modelo PCA bidimensional de los vectores de palabras utilizando la clase PCA de scikit-learn de la siguiente manera.\n",
    "\n",
    "```python\n",
    "    pca = PCA(n_components=2)\n",
    "    result = pca.fit_transform(X)\n",
    "```\n",
    "\n",
    "La proyección resultante se puede trazar usando Matplotlib de la siguiente manera, sacando las dos dimensiones como\n",
    "coordenadas x e y.\n",
    "\n",
    "```python\n",
    "    pyplot.scatter(result[:, 0], result[:, 1])\n",
    "```\n",
    "\n",
    "Podemos ir un paso más allá y anotar los puntos en el gráfico con las propias palabras.\n",
    "```python\n",
    "    words = model.wv.index_to_key\n",
    "    for i, word in enumerate(words):\n",
    "        pyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "# define training data\n",
    "sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
    "\t\t\t['this', 'is', 'the', 'second', 'sentence'],\n",
    "\t\t\t['yet', 'another', 'sentence'],\n",
    "\t\t\t['one', 'more', 'sentence'],\n",
    "\t\t\t['and', 'the', 'final', 'sentence']]\n",
    "# train model\n",
    "model = Word2Vec(sentences, min_count=1)\n",
    "# fit a 2d PCA model to the vectors\n",
    "X = model.wv[model.wv.key_to_index]\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)\n",
    "# create a scatter plot of the projection\n",
    "pyplot.scatter(result[:, 0], result[:, 1])\n",
    "words = list(model.wv.index_to_key)\n",
    "for i, word in enumerate(words):\n",
    "\tpyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar el ejemplo crea un gráfico de dispersión con los puntos anotados con las palabras. Es difícil sacar mucho significado del gráfico dado que se utilizó un corpus tan pequeño para ajustar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section14\"></a>\n",
    "# <font color=\"#004D7F\" size=5>1.4. Cargar el Embedding de Word2Vec de Google</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modelo preentrenado no es más que un archivo que contiene tokens y sus vectores de palabras asociados. El modelo Google _Word2Vec_ preentrenado se entrenó con datos de noticias de Google (alrededor de 100 mil millones de palabras); contiene 3 millones de palabras y frases y se ajustó utilizando vectores de palabras de 300 dimensiones.\n",
    "Es un archivo de 1,53 Gigabytes. \n",
    "\n",
    "La librería `Gensim` proporciona herramientas para cargar este archivo. Específicamente, puede llamar a la función `KeyedVectors.load_word2vec_format()` para cargar este modelo en la memoria, por ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Se puede descargar [`GoogleNews-vectors-negative300.bin`](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# load the google word2vec model\n",
    "filename = 'data/GoogleNews-vectors-negative300.bin'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ejemplo popular descrito en conferencias y documentos de introducción es:\n",
    "\n",
    "`queen = (king - man) + woman`\n",
    "\n",
    "Es decir, la palabra reina es la palabra más cercana dada la sustracción de la noción de hombre de la de rey y la adición de la palabra mujer. La masculinidad en rey es reemplazada por la feminidad para darnos reina. Un concepto muy genial. Gensim proporciona una interfaz para realizar este tipo de operaciones en la función `most_similar()` en el modelo entrenado o cargado. Por ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Proyecto Google [Word2Vec](https://code.google.com/archive/p/word2vec/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118193507194519)]\n"
     ]
    }
   ],
   "source": [
    "# Check the \"most similar words\", using the default \"cosine similarity\" measure.\n",
    "# calculate: (king - man) + woman = ?\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ejecutar el ejemplo, se carga el modelo _Word2Vec_ previamente entrenado por Google y luego se calcula el `(king - man) + women = ?` operación en los vectores de palabras para esas palabras. La respuesta, como era de esperar, es `queen`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen: 0.9314\n"
     ]
    }
   ],
   "source": [
    "# Use a different similarity measure: \"cosmul\".\n",
    "result = model.most_similar_cosmul(positive=['woman', 'king'], negative=['man'])\n",
    "most_similar_key, similarity = result[0]  # look at the first match\n",
    "print(f\"{most_similar_key}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats: 0.8099\n"
     ]
    }
   ],
   "source": [
    "result = model.similar_by_word(\"cat\")\n",
    "most_similar_key, similarity = result[0]  # look at the first match\n",
    "print(f\"{most_similar_key}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cats', 0.8099379539489746),\n",
       " ('dog', 0.760945737361908),\n",
       " ('kitten', 0.7464985251426697),\n",
       " ('feline', 0.7326234579086304),\n",
       " ('beagle', 0.7150582671165466),\n",
       " ('puppy', 0.7075453400611877),\n",
       " ('pup', 0.6934291124343872),\n",
       " ('pet', 0.6891531348228455),\n",
       " ('felines', 0.6755931973457336),\n",
       " ('chihuahua', 0.6709762215614319)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the 5 most similar words to “car” or “minivan”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SUV', 0.8532192707061768), ('vehicle', 0.8175783753395081), ('pickup_truck', 0.7763688564300537), ('Jeep', 0.7567334175109863), ('Ford_Explorer', 0.7565720081329346)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(positive=['car', 'minivan'], topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the below does not belong in the sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n"
     ]
    }
   ],
   "source": [
    "print(model.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section15\"></a>\n",
    "# <font color=\"#004D7F\" size=5>1.5. Cargue la incrustación _GloVe_ de Stanford</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los investigadores de Stanford también tienen su propio algoritmo de Word Embedding llamado Vectores Global Vectors (_GloVe_). \n",
    "\n",
    "Al igual que _Word2Vec_, los investigadores de _GloVe_ también proporcionan vectores de palabras previamente entrenados, en este caso, una gran selección para elegir. Puede descargar los vectores de palabras previamente entrenados de _GloVe_ y cargar fácilmente con _Gensim_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Se puede descargar [`glove.6B.zip`](http://nlp.stanford.edu/data/glove.6B.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede descargar el modelo preentrenado de _GloVe_ más pequeño del sitio web de _GloVe_. Es un archivo zip de 822 Megabytes con 4 modelos diferentes (vectores de 50, 100, 200 y 300 dimensiones) entrenados en datos de\n",
    "Wikipedia con 6 mil millones de tokens y un vocabulario de 400,000 palabras. \n",
    "\n",
    "Trabajando con la versión de 100 dimensiones del modelo, podemos cargar el archivo a formato Word2Vec con la función `load_word2vec_format` de la clase `KeyedVectors`.\n",
    "\n",
    "Ahora podemos cargarlo y realizar lo mismo que la prueba `(king - man) + woman = ?` como en el apartado anterior. \n",
    "\n",
    "La lista completa de códigos se proporciona a continuación. Tenga en cuenta que el archivo convertido tiene formato ASCII, no binario, por lo que establecemos `binary=False` al cargar y el `no_header=True` ya que no tiene encabezado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Información sobre la API Gensim [`scripts.glove2word2vec`](https://radimrehurek.com/gensim/scripts/glove2word2vec.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Proyecto Stanford [GloVe](https://nlp.stanford.edu/projects/glove/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7698540687561035)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "# read de file\n",
    "glove_input_file = 'data/glove.6B/glove.6B.100d.txt'\n",
    "# load the converted model\n",
    "model = KeyedVectors.load_word2vec_format(glove_input_file, binary=False, no_header=True)\n",
    "# calculate: (king - man) + woman = ?\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\" size=6>2. Word Embedding en Keras</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras ofrece una capa Embedding que se puede usar para redes neuronales en datos de texto. \n",
    "- Requiere que los datos de entrada estén codificados en números enteros, de modo que cada palabra esté representada por un número entero único. \n",
    "- Para ello utilizamos la API `Tokenizer` de Keras.\n",
    "\n",
    "La capa `Embedding` se define como la primera capa oculta de una red. Debe especificar 3 argumentos:\n",
    "- __`input_dim`__: este es el tamaño del vocabulario en los datos de texto. \n",
    "    - Por ejemplo, si sus datos están codificados en números enteros con valores entre 0 y 10, entonces el tamaño del vocabulario sería de 11 palabras.\n",
    "- __`output_dim`__: este es el tamaño del espacio vectorial en el que se incrustarán las palabras. Define el tamaño de los vectores de salida de esta capa para cada palabra. \n",
    "    - Por ejemplo, podría ser 32 o 100 o incluso más. Pruebe diferentes valores para su problema.\n",
    "- __`input_length`__: esta es la longitud de las secuencias de entrada para cualquier capa de entrada de un modelo de Keras. \n",
    "    - Por ejemplo, si todos sus documentos de entrada se componen de 1000 palabras, esto sería 1000.\n",
    "\n",
    "Por ejemplo, a continuación definimos una capa `Embedding` con un vocabulario de 200 (por ejemplo, palabras\n",
    "codificadas con números enteros de 0 a 199, inclusive), un espacio vectorial de 32 dimensiones en el que se incrustarán palabras y documentos de entrada que tienen 50 palabras cada uno.\n",
    "\n",
    "```python\n",
    "    e = Embedding(200, 32, input_length = 50)\n",
    "```\n",
    "\n",
    "- La capa `Embedding` tiene pesos que se aprenden. \n",
    "    - Si guarda su modelo en un archivo, esto incluirá pesos para la capa `Embedding`. \n",
    "- La salida de la capa `Embedding` es un vector ___2D___ con una incrustación para cada palabra en la secuencia de palabras de entrada (documento de entrada). \n",
    "- Si desea conectar una capa `Dense` directamente a una capa `Embedding`, primero debe aplanar la matriz de salida 2D a un vector 1D usando la capa `Flatten`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section21\"></a>\n",
    "# <font color=\"#004D7F\" size=5>2.1. Ejemplo de aprendizaje de Embedding</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiremos un pequeño problema donde tenemos 10 documentos de texto, cada uno con un comentario sobre un trabajo enviado por un estudiante. Cada documento de texto se clasifica como __positivo 1__ o __negativo 0__. Este es un problema de análisis de reseñas simple.\n",
    "\n",
    "Primero, definiremos los documentos y sus etiquetas de clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 15:35:16.603868: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-05 15:35:24.297982: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/include:/usr/local/cuda-11.0/lib64:\n",
      "2022-12-05 15:35:24.298522: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/include:/usr/local/cuda-11.0/lib64:\n",
      "2022-12-05 15:35:24.298573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "# define documents\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, podemos codificar con enteros cada documento:\n",
    "- Esto significa que como entrada, la capa `Embedding` tendrá secuencias de números enteros. \n",
    "- Keras proporciona la función `one_hot()` que crea un hash de cada palabra como una codificación de enteros. \n",
    "- Estimaremos el tamaño del vocabulario de 50, que es mucho más grande de lo necesario para reducir la probabilidad de colisiones de la función hash.\n",
    "\n",
    "Imprimimos los documentos codificados en enteros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35, 4], [6, 23], [42, 37], [10, 23], [33], [33], [8, 37], [29, 6], [8, 23], [45, 12, 4, 44]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode the documents\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Las secuencias tienen diferentes longitudes y Keras prefiere que las **entradas estén vectorizadas y que todas las entradas tengan la misma longitud**. \n",
    "- Rellenaremos todas las secuencias de entrada para que tengan una longitud de 4. \n",
    "    - Podemos hacer esto con la función `pad_sequences()`.\n",
    "\n",
    "Se imprimen las versiones padded de cada documento, haciéndolos de longitud uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  4  0  0]\n",
      " [ 6 23  0  0]\n",
      " [42 37  0  0]\n",
      " [10 23  0  0]\n",
      " [33  0  0  0]\n",
      " [33  0  0  0]\n",
      " [ 8 37  0  0]\n",
      " [29  6  0  0]\n",
      " [ 8 23  0  0]\n",
      " [45 12  4 44]]\n"
     ]
    }
   ],
   "source": [
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora estamos listos para definir nuestra capa `Embedding` como parte de nuestro modelo de red neuronal. \n",
    "- La capa `Embedding` tiene un vocabulario de 50 y una longitud de entrada de 4. \n",
    "- Elegiremos un pequeño espacio de incrustación de 8 dimensiones. \n",
    "- El modelo es un modelo de clasificación binaria simple.\n",
    "- Es importante destacar que la salida de la capa `Embedding` será de 4 vectores de 8 dimensiones cada uno, uno para cada palabra. \n",
    "- Aplanamos esto a un vector de 32 elementos para pasar a la capa de salida `Dense`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 15:40:05.326557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-05 15:40:05.802296: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-05 15:40:05.803496: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-05 15:40:06.117534: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-05 15:40:06.120772: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-05 15:40:06.122060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-05 15:40:06.123212: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-05 15:40:10.482430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-05 15:40:10.483645: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-05 15:40:10.484455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-05 15:40:10.485716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3375 MB memory:  -> device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0, compute capability: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 4, 8)              400       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que, como se esperaba, la salida de la capa `Embedding` es una matriz de $4 \\times 8$ y la capa `Flatten` la reduce a un vector de 32 elementos.\n",
    "\n",
    "Finalmente, podemos ajustar y evaluar el modelo de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 15:40:59.302974: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1df28c30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-05 15:40:59.304236: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Quadro M1200, Compute Capability 5.0\n",
      "2022-12-05 15:40:59.357316: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-12-05 15:41:00.024023: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-12-05 15:41:00.275754: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.000001\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se imprime el Accuracy del modelo entrenado, mostrando que aprendió el entrenamiento conjunto de datos perfectamente (lo cual no es sorprendente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section22\"></a>\n",
    "# <font color=\"#004D7F\" size=5>2.2. Ejemplo de uso de _GloVe_ preentrenado</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de descargar y descomprimir, verá algunos archivos, uno de los cuales es `glove.6B.100d.txt`, que contiene una versión de 100 dimensiones de la incrustación. Si mira dentro del archivo, verá un token (palabra) seguido de los pesos (100 números) en cada línea. Por ejemplo, a continuación se muestra la primera línea del archivo de texto ASCII incrustado que muestra la incrustación.\n",
    "\n",
    "```text\n",
    "    the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en la sección anterior, el primer paso es definir los ejemplos, codificarlos como números enteros y luego rellenar las secuencias para que tengan la misma longitud. \n",
    "\n",
    "En este caso, necesitamos poder mapear palabras a números enteros así como números enteros a palabras. Keras proporciona una clase `Tokenizer` que:\n",
    "- se puede ajustar a los datos de entrenamiento, \n",
    "- puede convertir texto en secuencias de manera consistente llamando al método `texts_to_functions()` en la clase `Tokenizer`, y \n",
    "- proporciona acceso a la asignación de palabras a números enteros del diccionario en un atributo de índice de palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 2], [3, 1], [7, 4], [8, 1], [9], [10], [5, 4], [11, 3], [5, 1], [12, 13, 2, 14]]\n",
      "[[ 6  2  0  0]\n",
      " [ 3  1  0  0]\n",
      " [ 7  4  0  0]\n",
      " [ 8  1  0  0]\n",
      " [ 9  0  0  0]\n",
      " [10  0  0  0]\n",
      " [ 5  4  0  0]\n",
      " [11  3  0  0]\n",
      " [ 5  1  0  0]\n",
      " [12 13  2 14]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "# define documents\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(encoded_docs)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, debemos cargar todo el archivo de Word Embeddings de _GloVe_ en la memoria como un diccionario de palabras para la matriz de incrustaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('data/glove.6B/glove.6B.100d.txt', mode='rt', encoding='utf-8')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, debemos crear una matriz de una incrustación para cada palabra en el conjunto de datos de entrenamiento. \n",
    "\n",
    "Podemos hacerlo enumerando todas las palabras únicas en `Tokenizer.word_index` y ubicando el vector de peso de incrustación de la incrustación de _GloVe_ cargada. \n",
    "\n",
    "El resultado es una matriz de pesos solo para palabras que veremos durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos definir nuestro modelo, ajustarlo y evaluarlo como antes. \n",
    "- La diferencia clave es que la capa `Embedding` se puede establecer con los pesos de Word Embeddings de _GloVe_. \n",
    "- Elegimos la versión de 100 dimensiones, por lo tanto, la capa `Embedding` debe definirse con `output_dim` establecida en 100. \n",
    "- Finalmente, no queremos actualizar los pesos de las palabras aprendidas en este modelo, por lo tanto, estableceremos el atributo `trainable` para que el modelo sea `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 4, 100)            1500      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 401       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,901\n",
      "Trainable params: 401\n",
      "Non-trainable params: 1,500\n",
      "_________________________________________________________________\n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "model.summary()\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sectionEJ\"></a>\n",
    "# <font color=\"#004D7F\" size=6><i class=\"fa fa-pencil-square-o\" aria-hidden=\"true\" style=\"color:#113D68\"></i>  Ejercicios</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a realizar un ejemplo con Word2Vec. En este ejemplo se utiliza un conjunto de datos compuesto por gráficos de películas (en formato txt). El archivo se llama `movie_plots.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sectionEJ1\"></a>\n",
    "# <font color=\"#004D7F\" size=5>Ejercicio 1</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez descargado el conjunto de datos, hay que limpiarlo y preprocesarlo antes de generar las incrustaciones. \n",
    "\n",
    "El preprocesamiento incluye tareas como la tokenización, el minúsculas y la eliminación de palabras vacías. Gensim incluye un sencillo método de preprocesamiento que realiza estas tareas automáticamente `gensim.utils.simple_preprocessing(line)`.\n",
    "\n",
    "Crea una función que haga este procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "def process_input_file(input_file):\n",
    "  token_list=[]\n",
    "  with open(input_file,'r',encoding='utf-8',errors='ignore') as f:\n",
    "    for line in f:\n",
    "      token_list.append(gensim.utils.simple_preprocess(line))\n",
    "  return token_list\n",
    "\n",
    "documents=process_input_file(\"data/movie_plots.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que se realiza este procesamiento previo, terminamos con una lista plana de tokens significativos, siguiendo el mismo orden de aparición que en los documentos de entrada. Esto asegura que se mantenga el contexto de la palabra. \n",
    "\n",
    "Para asegurarnos de que se cumple esta restricción, imprime la primera oración. Verifica que todos los tokens se han convertido a minúsculas y se han eliminado algunas palabras vacías. Aún así, el contexto de la oración original permanece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bartender',\n",
       " 'is',\n",
       " 'working',\n",
       " 'at',\n",
       " 'saloon',\n",
       " 'serving',\n",
       " 'drinks',\n",
       " 'to',\n",
       " 'customers',\n",
       " 'after',\n",
       " 'he',\n",
       " 'fills',\n",
       " 'stereotypically',\n",
       " 'irish',\n",
       " 'man',\n",
       " 'bucket',\n",
       " 'with',\n",
       " 'beer',\n",
       " 'carrie',\n",
       " 'nation',\n",
       " 'and',\n",
       " 'her',\n",
       " 'followers',\n",
       " 'burst',\n",
       " 'inside',\n",
       " 'they',\n",
       " 'assault',\n",
       " 'the',\n",
       " 'irish',\n",
       " 'man',\n",
       " 'pulling',\n",
       " 'his',\n",
       " 'hat',\n",
       " 'over',\n",
       " 'his',\n",
       " 'eyes',\n",
       " 'and',\n",
       " 'then',\n",
       " 'dumping',\n",
       " 'the',\n",
       " 'beer',\n",
       " 'over',\n",
       " 'his',\n",
       " 'head',\n",
       " 'the',\n",
       " 'group',\n",
       " 'then',\n",
       " 'begin',\n",
       " 'wrecking',\n",
       " 'the',\n",
       " 'bar',\n",
       " 'smashing',\n",
       " 'the',\n",
       " 'fixtures',\n",
       " 'mirrors',\n",
       " 'and',\n",
       " 'breaking',\n",
       " 'the',\n",
       " 'cash',\n",
       " 'register',\n",
       " 'the',\n",
       " 'bartender',\n",
       " 'then',\n",
       " 'sprays',\n",
       " 'seltzer',\n",
       " 'water',\n",
       " 'in',\n",
       " 'nation',\n",
       " 'face',\n",
       " 'before',\n",
       " 'group',\n",
       " 'of',\n",
       " 'policemen',\n",
       " 'appear',\n",
       " 'and',\n",
       " 'order',\n",
       " 'everybody',\n",
       " 'to',\n",
       " 'leave']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sectionEJ2\"></a>\n",
    "# <font color=\"#004D7F\" size=5>Ejercicio 2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que tenemos nuestro documento tokenizado, podemos inicializar y entrenar nuestro modelo Word2Vec. Antes de entrenar el modelo, se deben definir ciertos parámetros:\n",
    "- __`vector_size`__: Dimensionalidad de los vectores de palabras. Debe ser coherente con la dimensionalidad del corpus del documento y el tamaño del vocabulario. **Como tenemos un corpus reducido, un tamaño de 100 debería ser adecuado para nuestro problema.**\n",
    "- __`window`__: Dimensión de la ventana de contexto. Debería ser suficiente para contextualizar una palabra. **En este ejemplo, usaremos un tamaño 10.**\n",
    "- __`min_count`__: Número mínimo de apariciones de una palabra en el corpus a considerar para la incrustación. **Consideraremos que al menos 3 repeticiones de una palabra son suficientes para ser incrustado**.\n",
    "- __`sg`__: Algoritmo de entrenamiento: 1 para skip-gram; 0 para CBOW. **Usaremos skip-gram**.\n",
    "- __`epochs`__: Número de iteraciones de entrenamiento. Haremos **5 iteraciones**.\n",
    "- __`seed`__: semilla de inicialización. Usaremos 1852 como nuestra semilla.\n",
    "\n",
    "Cree un objeto model llamadon a `Word2Vec` de Gensim con la configuración anterior y proceda a su entrenamiento con `train()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.Word2Vec(documents, vector_size=100, window=10, min_count=3, sg=1, epochs=4, seed=1852)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10490560, 13824376)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(documents, total_examples=w2v_model.corpus_count, epochs=w2v_model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que se ha entrenado el modelo, podemos extraer las incrustaciones de palabras generadas (en forma de un diccionario de Python) y consultarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_embeddings=w2v_model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sectionEJ3\"></a>\n",
    "# <font color=\"#004D7F\" size=5>Ejercicio 3</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con las incrustaciones extraídas, podemos realizar ciertas operaciones como:\n",
    "\n",
    "**Preguntar por la palabra más parecida a una palabra dada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dancer', 0.7542173862457275),\n",
       " ('performer', 0.7404608130455017),\n",
       " ('nightclub', 0.7175503373146057),\n",
       " ('soprano', 0.7144984006881714),\n",
       " ('starlet', 0.7025715708732605),\n",
       " ('superstar', 0.7015737295150757),\n",
       " ('ingenue', 0.6971699595451355),\n",
       " ('blondell', 0.691870391368866),\n",
       " ('sultry', 0.6902326345443726),\n",
       " ('vocalist', 0.6848028898239136)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word=\"singer\"\n",
    "w2v_embeddings.most_similar(positive=word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si solo queremos obtener las _N_ palabras más similares, entonces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dogs', 0.6922426819801331),\n",
       " ('stray', 0.6798008680343628),\n",
       " ('puppy', 0.6707093715667725)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word=[\"dog\"]\n",
    "n=3\n",
    "w2v_embeddings.most_similar(positive=word,topn=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sectionEJ4\"></a>\n",
    "# <font color=\"#004D7F\" size=5>Ejercicio 4</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Medir la similitud entre pares de palabras**\n",
    "\n",
    "Dadas dos palabras existentes en el corpus, podemos medir la similitud existente entre las dos. Si el modelo se entrena adecuadamente, las palabras que se refieren a conceptos similares, como los sinónimos, deberían obtener puntajes altos de similitud.\n",
    "\n",
    "Mide la similitud entre _movie_ y _film_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82893413"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1=\"movie\"\n",
    "word2=\"film\"\n",
    "w2v_embeddings.similarity(word1,word2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por el contrario, los antónimos deberían recibir puntuaciones bajas.\n",
    "\n",
    "Mide la similitud entre _great_ y _awful_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32233217"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1=\"great\"\n",
    "word2=\"awful\"\n",
    "w2v_embeddings.similarity(word1,word2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sectionEJ5\"></a>\n",
    "# <font color=\"#004D7F\" size=5>Ejercicio 5</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recuperar el Embedding de una palabra dada**\n",
    "\n",
    "Hay dos formas de recuperar el vector de una palabra. La primera forma es usando el método integrado `get_vector()`. Este modelo devuelve la incrustación asociada con la palabra de entrada si existe en el vocabulario y el error en caso contrario.\n",
    "\n",
    "Utilícelo para la palabra beach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09560033, -0.03120027,  0.0207166 , -0.42926332, -0.01053735,\n",
       "        0.26626188,  0.20543277, -0.00266073, -0.19645952, -0.1586069 ,\n",
       "       -0.47515127,  0.29729855, -0.61440504,  0.21458566, -0.18524756,\n",
       "       -0.08926032, -0.14477904,  0.343519  , -0.00412936,  0.25272048,\n",
       "       -0.07780255, -0.06647279,  0.08216458,  0.01228995, -0.09513793,\n",
       "       -0.3859143 , -0.30906942, -0.26056147, -0.09905334,  0.25973257,\n",
       "        0.03177204, -0.2140215 , -0.1159922 ,  0.52084816, -0.01291936,\n",
       "        0.01037219,  0.09694981, -0.3663353 ,  0.3576129 ,  0.38664055,\n",
       "       -0.3601496 ,  0.13518448, -0.7304878 , -0.23689681,  0.05383343,\n",
       "       -0.09771732,  0.32411745, -0.9362737 , -0.4343401 , -0.07585958,\n",
       "       -0.00978419, -0.33632115,  0.02170849, -0.297619  ,  0.2529543 ,\n",
       "        0.25787318,  0.16942401,  0.22072574,  0.00362314, -0.17207937,\n",
       "        1.014553  , -0.05233747, -0.00123477, -0.00227715,  0.2380213 ,\n",
       "       -0.18401477, -0.3446305 , -0.14515032,  0.01325089,  0.05532356,\n",
       "        0.04041756,  0.2196228 , -0.11911522,  0.20619665, -0.49360922,\n",
       "        0.08794107,  0.5236747 , -0.01504897,  0.03828515,  0.10999516,\n",
       "       -0.03123301,  0.652125  ,  0.35633746,  0.04880004, -0.36888918,\n",
       "       -0.27168915, -0.12702961, -0.45935673,  0.06548139,  0.20656314,\n",
       "        0.273815  ,  0.15446311,  0.05488523, -0.26542625, -0.08862077,\n",
       "        0.45461702, -0.22734793, -0.43514943, -0.11305104,  0.10973048],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word=\"beach\"\n",
    "w2v_embeddings.get_vector(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo en cuenta que las incrustaciones de palabras se almacenan en forma de diccionario compuesto por tuplas _(palabra, vector)_, donde las palabras sirven como claves, obten el embedding de _beach_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09560033, -0.03120027,  0.0207166 , -0.42926332, -0.01053735,\n",
       "        0.26626188,  0.20543277, -0.00266073, -0.19645952, -0.1586069 ,\n",
       "       -0.47515127,  0.29729855, -0.61440504,  0.21458566, -0.18524756,\n",
       "       -0.08926032, -0.14477904,  0.343519  , -0.00412936,  0.25272048,\n",
       "       -0.07780255, -0.06647279,  0.08216458,  0.01228995, -0.09513793,\n",
       "       -0.3859143 , -0.30906942, -0.26056147, -0.09905334,  0.25973257,\n",
       "        0.03177204, -0.2140215 , -0.1159922 ,  0.52084816, -0.01291936,\n",
       "        0.01037219,  0.09694981, -0.3663353 ,  0.3576129 ,  0.38664055,\n",
       "       -0.3601496 ,  0.13518448, -0.7304878 , -0.23689681,  0.05383343,\n",
       "       -0.09771732,  0.32411745, -0.9362737 , -0.4343401 , -0.07585958,\n",
       "       -0.00978419, -0.33632115,  0.02170849, -0.297619  ,  0.2529543 ,\n",
       "        0.25787318,  0.16942401,  0.22072574,  0.00362314, -0.17207937,\n",
       "        1.014553  , -0.05233747, -0.00123477, -0.00227715,  0.2380213 ,\n",
       "       -0.18401477, -0.3446305 , -0.14515032,  0.01325089,  0.05532356,\n",
       "        0.04041756,  0.2196228 , -0.11911522,  0.20619665, -0.49360922,\n",
       "        0.08794107,  0.5236747 , -0.01504897,  0.03828515,  0.10999516,\n",
       "       -0.03123301,  0.652125  ,  0.35633746,  0.04880004, -0.36888918,\n",
       "       -0.27168915, -0.12702961, -0.45935673,  0.06548139,  0.20656314,\n",
       "        0.273815  ,  0.15446311,  0.05488523, -0.26542625, -0.08862077,\n",
       "        0.45461702, -0.22734793, -0.43514943, -0.11305104,  0.10973048],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_embeddings['beach']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sectionEJ6\"></a>\n",
    "# <font color=\"#004D7F\" size=5>Ejercicio 6</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtener la palabra más cercana a un vector dado**\n",
    "\n",
    "Como las palabras se representan en un espacio vectorial, podemos realizar ciertas operaciones, como la suma o la resta, que también dan como resultado vectores. Como estas operaciones se basan en la intuición y, por lo tanto, no son exactas, el resultado de una operación como esta no está relacionado directamente con una palabra. \n",
    "\n",
    "Podemos obtener la palabra más cercana a un vector dado con las palabras _music_ y _film_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('music', 0.8176624774932861),\n",
       " ('film', 0.8093442320823669),\n",
       " ('documentary', 0.7606794834136963),\n",
       " ('soundtrack', 0.7596319913864136),\n",
       " ('gershwin', 0.7518333792686462),\n",
       " ('movie', 0.7400728464126587),\n",
       " ('previn', 0.7384520173072815),\n",
       " ('theme', 0.7379338145256042),\n",
       " ('tchaikovsky', 0.7372975945472717),\n",
       " ('montage', 0.7340453863143921)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1=w2v_embeddings['music']\n",
    "vector2=w2v_embeddings['film']\n",
    "operation=vector1+vector2\n",
    "w2v_embeddings.similar_by_vector(operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sectionEJ7\"></a>\n",
    "# <font color=\"#004D7F\" size=5>Ejercicio 7</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detectar términos inadecuados en una lista de palabras**\n",
    "\n",
    "Dada una lista de palabras, podemos identificar cuál de ellas no está relacionada con el resto usando la función integrada `doesnt_match()`. Vea la salida para el siguiente vector: \n",
    "```python\n",
    "word_list=['cat','dog','mouse','actress','bird']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'actress'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list=['cat','dog','mouse','actress','bird']\n",
    "w2v_embeddings.doesnt_match(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sectionEJ8\"></a>\n",
    "# <font color=\"#004D7F\" size=5>Ejercicio 8</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Realizar analogías entre palabras**\n",
    "\n",
    "Una de las mayores mejoras introducidas por Word2Vec fue la capacidad de realizar analogías entre palabras. Esta propiedad no solo pone en evidencia la calidad de las incrustaciones generadas por el modelo, sino que permite la representación **aproximada** de palabras que no se ven durante el entrenamiento.\n",
    "\n",
    "Utilícelo con las siguientes palabras: _cat_, _cats_ y _mouse_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cats', 0.8237479329109192),\n",
       " ('cat', 0.6796796321868896),\n",
       " ('mice', 0.6646682024002075),\n",
       " ('garon', 0.6154602766036987),\n",
       " ('dogs', 0.6033499836921692),\n",
       " ('felines', 0.600951611995697),\n",
       " ('mutt', 0.600653350353241),\n",
       " ('shrug', 0.5995326042175293),\n",
       " ('duplicates', 0.5964731574058533),\n",
       " ('canary', 0.5950862169265747)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1=w2v_embeddings['cat']\n",
    "word2=w2v_embeddings['cats']\n",
    "word3=w2v_embeddings['mouse']\n",
    "operation=word1-word3+word2\n",
    "w2v_embeddings.similar_by_vector(operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una forma más limpia y rápida de realizar inferencia analógica es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mice', 0.7246355414390564),\n",
       " ('canary', 0.6622194647789001),\n",
       " ('shrug', 0.6573811769485474),\n",
       " ('felines', 0.65106600522995),\n",
       " ('duplicates', 0.6507408022880554),\n",
       " ('kennel', 0.6485415697097778),\n",
       " ('feline', 0.6468013525009155),\n",
       " ('canine', 0.6461802124977112),\n",
       " ('dogs', 0.6455145478248596),\n",
       " ('garon', 0.6414704918861389)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_embeddings.most_similar(positive=['cat', 'cats'], negative=['mouse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
